<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8">

        <title>Network In Network</title>

        <meta name="description" content="A framework for easily creating beautiful presentations using HTML">
        <meta name="author" content="Benedict Etzel">

        <meta name="apple-mobile-web-app-capable" content="yes" />
        <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/night.css" id="theme">

        <!-- Code syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- Printing and PDF exports -->
        <script>
            var link = document.createElement('link');
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match(/print-pdf/gi) ? 'css/print/pdf.css' : 'css/print/paper.css';
            document.getElementsByTagName('head')[0].appendChild(link);
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->
    </head>

    <body>

        <div class="reveal">

            <!-- Any section element inside of this container is displayed as a slide -->
            <div class="slides">
                <section style="text-align: left;">
                    <h2>Network In Network</h2>
                    <h4>Paper von Min Lin, Qiang Chen und Shuicheng Yan</h4>
                    <address><small>Benedict Etzel<br>Universität zu Lübeck</small></address>
                </section>

                <!--<section>
                        <blockquote style="padding: 20px 30px;">
                            <p>„Rather than saying that layers in CNN are extracting more and more abstract features, I would say they are just extracting features that are spatially larger and larger.“</p>
                            <footer style="text-align: right;">&mdash; Min Lin</footer>
                        </blockquote>
                </section>-->

                <section>
                    <section data-markdown>
                        <script type="text/template">
                            ## Inhalt

                            1. Einführung
                            2. MLP Convolutional Layers
                            3. Global Average Pooling
                            4. Benchmarks
                            5. Fazit
                            6. Quellen
                            7. Fragen
                        </script>
                    </section>
                </section>

                <section>
                    <section>
                        <h2>Einführung</h2>

                        <ul>
                            <li class="fragment"><p>Ziel: Abstraktion von Datensätzen</p>
                                <ul>
                                    <li>Einteilung in Kategorien</li>
                                    <li>meist 2D, sehr klein (32×32)</li>
                                </ul>
                            </li>
                            <li class="fragment"><p>Convolutional Neural Networks</p>
                                <ul>
                                    <li class="fragment">Extraktion von Konzepten („features“)
                                        <ul>
                                            <li>Form</li>
                                            <li>Farbe</li>
                                        </ul>
                                    </li>
                                    <li class="fragment">Zuordnung: Features → Klassen
                                        <ul>
                                            <li>Rot → Apfel</li>
                                            <li>Gelb → Banane</li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>
                        </ul>
                        <aside class="notes">
                            <ul>
                                <li><p>Neural Networks (Erfassung Gesamtbild, räumliche Informationen verloren)</p>
                            </ul>
                        </aside>
                    </section>

                    <section>
                        <h3 id="convolutional-neural-networks">Convolutional Neural Networks</h3>
                        <ul>
                            <li class="fragment"><p>Schichten: Convolutional &amp; (Max-)Pooling + vollvernetzt + Softmax</p>
                            </li>
                            <li class="fragment"><p>Erfassung von Konzepten</p>
                            </li>
                            <li class="fragment">Vordere Schichten: konkreter<ul>
                                    <li>Kanten</li>
                                    <li>Ecken</li>
                                </ul>
                            </li>
                            <li class="fragment"><p>Hintere Schichten: abstrakter</p>
                                <ul>
                                    <li>Frucht</li>
                                    <li>Tier</li>
                                </ul>
                            </li>
                            <li class="fragment"><p>Backpropagation</p>
                            </li>
                        </ul>
                        <p class="fragment">Sind die Konzepte überhaupt linear trennbar?</p>
                        <aside class="notes">
                            <ul>
                                <li>Convolutional → Feature-Extraktion</li>
                                <li>Pooling → Verringerung Varianz</li>
                                <li>Vollvernetzt → Assoziation</li>
                                <li>Mehr Filter reichen auch</li>
                            </ul>
                        </aside>
                    </section>

                    <section>
                        <h2>Network in Network</h2>

                        <ul>
                            <li class="fragment"><p>Grundidee: Multilayer-Perzeptrone anstelle von linearen Filtern</p>
                                <ul>
                                    <li class="fragment">Funktionsapproximatoren</li>
                                    <li class="fragment">Aktivierungen entsprechen den Konzepten</li>
                                </ul>
                            </li>
                            <li class="fragment"><p>Vollvernetzte Schicht nun nicht mehr nötig</p></li>
                            <li class="fragment"><p>Feature Maps der letzten Schicht entsprechen bereits Konfidenz</p></li>
                    </section>

                    <section>
                        <h3>Network in Network</h3>
                        <figure>
                            <img style="padding: 50px;" src="nin.png" alt="Network In Network-Struktur">
                            <figcaption style="text-align:right;"><small>Lin et al.: Network In Network</small></figcaption>
                            <figcaption>Struktur eines „Network In Network“-Systems</figcaption>
                        </figure>
                    </section>
                </section>

                <section>
                    <section>
                        <h2>MLP Convolutional Layers</h2>
                        <ul>
                            <li class="fragment">Problematik der CNN-Struktur
                                <ul>
                                    <li>Benötigen übermäßig viele Filter für nichtlineare Teilprobleme</li>
                                    <li>Zu viele Feature Maps &rightarrow; Rechenaufwand explodiert</li>                                    
                                </ul>
                            </li>
                            <li class="fragment"><p>Lin: <q>„In conventional CNN, the abstraction of each local patch is done through a linear classifier and a non-linear activation function [...] definitely not a strong abstraction“</q></p></li>
                        </ul>
                        <p class="fragment">&DoubleRightArrow; „Starke Abstraktion“ ist besser</p>
                    </section>
                    <section>
                        <h3>„mlpconv“</h3>
                        <ul>
                            <li class="fragment">Warum MLPs?
                                <ul>
                                    <li class="fragment">Bereits viel erforscht</li>
                                    <li class="fragment">Eignen sich gut für Backpropagation</li>
                                    <li class="fragment">Weitere Vertiefung möglich</li>
                                </ul></li>
                            <li class="fragment"><p>Bessere Funktionsapproximierung (vgl. Maxout)</p></li>
                            <li class="fragment"><p>Versteckte Schichten sind geteilt</p></li>
                        </ul>
                        <p class="fragment">Wie assoziieren wir Klassen?</p>
                    </section>
                </section>

                <section>
                    <h3>Zur Erinnerung</h3>
                    <ul>
                        <li class="fragment">Klassifikation in CNNs
                            <ul>
                                <li class="fragment">Letzte Schicht liefert höchste Abstraktion</li>
                                <li class="fragment">Vektorisierung &rarr; Vollvernetzte Schicht &rarr; Softmax</li>
                                <li class="fragment">Training in vollvernetzter Schicht (und den convolutional layers)</li>
                            </ul></li>
                        <li class="fragment"><p>Problem: Overfitting <span class="fragment">&DoubleRightArrow; Dropout</span></p></li>
                    </ul>
                    <p class="fragment">Gibt es einen einfachereren Ansatz mit MLPs?</p>
                </section>
                <section>
                    <section>
                        <h2>Global Average Pooling</h2>
                        <ul>
                            <li class="fragment"><p>Durchschnitt jeder Feature Map &rightarrow; Softmax</p></li>
                            <li class="fragment"><p>Zahl der Feature Maps = Zahl der Kategorien</p></li>

                            <li class="fragment">Erzwingt Zugehörigkeit zwischen Kategorien und Feature Maps
                                <ul>
                                    <li class="fragment">Speziell gut mit den MLP-Schichten</li>
                                    <li class="fragment">Feature Maps entsprechen Konfidenz</li>
                                    <li class="fragment">Weniger Overfitting</li>
                                </ul>
                            </li>
                        </ul>
                    </section>

                    <section>
                        <h3>Im Vergleich</h3>
                        <table class="fragment" style="font-size: 0.75em;">
                            <caption align="bottom">CIFAR-10</caption>
                            <tr><th>Methode</th><th>Testfehler</th></tr>
                            <tr><td>mlpconv + vollvernetzt</td><td>11.59%</td></tr>
                            <tr><td>mlpconv + vollvernetzt + Dropout</td><td>10.88%</td></tr>
                            <tr><td><em>mlpconv + Global Average Pooling</em></td><td>10.41%</td></tr>
                        </table>
                    </section>

                    <section>
                        <h3>Kategorie &LeftRightArrow; Feature Map-Korrelation</h3>
                        <figure>
                            <img src="mlpconv-activations.png" alt="MLP-Aktivierungen">
                            <figcaption style="text-align:right;"><small>Lin et al.: Network In Network</small></figcaption>
                            <figcaption>Top 10% der Aktivierungen der letzten Schicht</figcaption>
                        </figure>
                    </section>
                </section>

                <section>
                    <section>
                        <h2>Benchmarks</h2>
                    </section>

                    <section>
                        <h3>CIFAR-10</h3>
                        <p class="fragment">Fotos (32&times;32 RGB) &middot; 50.000 + 10.000 Stück &middot; 10 Kategorien</p>
                        <div class="fragment">
                            <div style="display: inline-block;">
                                <table style="font-size: 0.75em;">
                                    <caption align="bottom">Rohdaten</caption>
                                    <tr><th>Methode</th><th>Testfehler</th></tr>
                                    <tr><td>Stochastisches Pooling</td><td>15.13%</td></tr>
                                    <tr><td>CNN + Spearmint</td><td>11.68%</td></tr>
                                    <tr><td>Konv. Maxout + Dropout</td><td>11.68%</td></tr>
                                    <tr><td><em>NIN + Dropout</em></td><td><em>10.41%</em></td></tr>                            
                                </table>
                            </div>
                            <div style="display: inline-block; margin-left: 40px;">
                                <table style=" font-size: 0.75em;">
                                    <caption align="bottom">Vorverarbeitete Daten*</caption>
                                    <tr><th>Methode</th><th>Testfehler</th></tr>
                                    <tr><td>CNN + Spearmint</td><td>11.68%</td></tr>
                                    <tr><td>Konv. Maxout + Dropout</td><td>15.13%</td></tr>
                                    <tr><td>DropConnect + 12 Netzwerke</td><td>11.68%</td></tr>
                                    <tr><td><em>NIN + Dropout</em></td><td><em>10.41%</em></td></tr>                            
                                </table>
                            </div>
                            <p style="text-align: right"><small>*Kontrast erhöht und aufgehellt</small></p>
                        </div>
                    </section>

                    <section>
                        <h3>CIFAR-100</h3>
                        <p class="fragment">Fotos (32&times;32 RGB) &middot; 50.000 + 10.000 Stück &middot; 100 Kategorien</p>
                        <table class="fragment" style="font-size: 0.75em;">
                            <tr><th>Methode</th><th>Testfehler</th></tr>
                            <tr><td>Gelerntes Pooling</td><td>43.71%</td></tr>
                            <tr><td>Stochastisches Pooling</td><td>42.51%</td></tr>
                            <tr><td>Konv. Maxout + Dropout</td><td>38.57%</td></tr>
                            <tr><td>Tree based priors</td><td>36.85%</td></tr>
                            <tr><td><em>NIN + Dropout</em></td><td><em>35.68%</em></td></tr>
                        </table>
                    </section>

                    <section>
                        <h3>Street View House Numbers</h3>
                        <p class="fragment">Ziffern (32&times;32 RGB) &middot; Hausnummern</p>
                        <table class="fragment" style="font-size: 0.75em;">
                            <tr><th>Methode</th><th>Testfehler</th></tr>
                            <tr><td>Stochastisches Pooling</td><td>2.80%</td></tr>
                            <tr><td>Rectifier + Dropout</td><td>2.78%</td></tr>
                            <tr><td>Rectifier + Dropout + Synthetic Translation</td><td>2.68%</td></tr>
                            <tr><td>Konv. Maxout + Dropout</td><td>2.47%</td></tr>
                            <tr><td><em>NIN + Dropout</em></td><td><em>2.35%</em></td></tr>
                            <tr><td>Multi-digit Number Recognition</td><td>2.16%</td></tr>
                            <tr><td>DropConnect</td><td>1.94%</td></tr>
                        </table>
                    </section>

                    <section>
                        <h3>MNIST</h3>
                        <p class="fragment">Ziffern (28&times;28 S/W) &middot; Handgeschrieben</p>
                        <table class="fragment" style="font-size: 0.75em;">
                            <tr><th>Methode</th><th>Testfehler</th></tr>
                            <tr><td>K-NN (shape context matching)</td><td>0.63%</td></tr>
                            <tr><td>2-Schicht CNN + 2-Schicht NN</td><td>0.53%</td></tr>
                            <tr><td><em>NIN + Dropout</em></td><td><em>0.47%</em></td></tr>
                            <tr><td>Konv. Maxout + Dropout</td><td>0.45%</td></tr>
                            <tr><td>35 CNNs</td><td>0.23%</td></tr>
                        </table>
                    </section>

                    <section>
                        <h3>Bonus: ImageNet</h3>
                        <p class="fragment">&gt;100.000 Kategorien &middot; ~1000 Bilder pro Kategorie</p>
                        <table class="fragment" style="font-size: 0.75em;">
                            <tr><th>Methode</th><th>Parameter</th><th>Performanz (Top 1)</th><th>Trainingszeit</th></tr>
                            <tr><td>AlexNet</td><td>60 Millionen (230 Megabytes)</td><td>40.7%</td><td>8 Tage</td></tr>
                            <tr><td><em>NIN</em></td><td><em>7.5 Millionen (29 Megabytes)</em></td><td><em>39.2%</em></td><td><em>4 Tage</em></td></tr>
                        </table>
                    </section>
                </section>

                <section>
                    <h2>Fazit</h2>
                    <ul>
                        <li class="fragment"><p>„Networks in Network“ als State-of-the-Art-Alternative zu klassischen CNNs</p></li>
                        <li class="fragment">Strukturell ähnlich; jedoch Teilprobleme verlagert
                            <ul>
                                <li>MLP Convolutional Layers</li>
                                <li>Global Average Pooling</li>
                            </ul></li>
                        <li class="fragment"><p>Vergleichbare Ergebnisse mit viel weniger Parametern</p></li>
                    </ul>
                    <p class="fragment">In Zukunft? <span class="fragment">&DoubleRightArrow; „Deep NINs”</span></p>
                    <aside class="notes">
                        <ul>
                            <li>Global Pooling: Einfachere Interpretation und weniger Overfitting</li>
                        </ul>
                    </aside>
                </section>

                <section>
                    <h2>Quellen</h2>
                    <ul>
                        <li>Min Lin, Qiang Chen, Shuicheng Yan: Network In Network, 2013</li>
                        <li>Min Lin: <a href="http://linmin.me/post/70873519977/some-more-explanations-of-network-in-network" target="_blank">Some more explanations of Network in Network</a> (entnommen am 01.07.2015)</li>
                        <!--<li>Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron Courville, Yoshua Bengio: Maxout Networks, 2013</li>-->
                        <li>Yann LeCun, Corinna Cortes, Christopher J.C. Burges: <a href="http://yann.lecun.com/exdb/mnist/" target="_blank">The MNIST database of handwritten digits</a> (entnommen am 01.07.2015)</li>
                        <li>Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng: Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning, 2011</li>
                        <li>Jian Dong, Min Lin, Yunchao Wei, Qiang Chen: <a href="http://www.image-net.org/challenges/LSVRC/2014/slides/ILSVRC2014_NUS_release.pdf" target="_blank">NIN, Good!</a>, 2014 (entnommen am 01.07.2015)</li>
                    </ul>
                </section>

                <section style="text-align: right;" data-transition="convex">
                    <h1>Fragen?</h1>
                </section>

                <section style="text-align: left;" data-transition="zoom">
                    <h1>Ende!</h1>
                    <p>
                        - Benedict Etzel <a href="mailto:benedict.etzel@student.uni-luebeck.de">&lt;benedict.etzel@student.uni-luebeck.de&gt;</a><br>
                        - <a href="https://github.com/beheh/uzl-machine-learning-seminar" target="_blank">https://github.com/beheh/uzl-machine-learning-seminar</a>
                    </p>
                </section>

            </div>

        </div>

        <script src="lib/js/head.min.js"></script>
        <script src="js/reveal.js"></script>

        <script>

            // Full list of configuration options available at:
            // https://github.com/hakimel/reveal.js#configuration
            Reveal.initialize({
                controls: false,
                progress: true,
                history: true,
                center: true,
                transition: 'slide', // none/fade/slide/convex/concave/zoom

                // Optional reveal.js plugins
                dependencies: [
                    {src: 'lib/js/classList.js', condition: function () {
                            return !document.body.classList;
                        }},
                    {src: 'plugin/markdown/marked.js', condition: function () {
                            return !!document.querySelector('[data-markdown]');
                        }},
                    {src: 'plugin/markdown/markdown.js', condition: function () {
                            return !!document.querySelector('[data-markdown]');
                        }},
                    {src: 'plugin/highlight/highlight.js', async: true, condition: function () {
                            return !!document.querySelector('pre code');
                        }, callback: function () {
                            hljs.initHighlightingOnLoad();
                        }},
                    {src: 'plugin/zoom-js/zoom.js', async: true},
                    {src: 'plugin/remotes/remotes.js', async: true},
                    {src: 'plugin/notes/notes.js', async: true}
                ]
            });
            Reveal.configure({slideNumber: 'c / t'});
        </script>

    </body>
</html>
